{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5BHXfOm_3JuY",
        "outputId": "1a4edeac-efda-47a2-e79c-c582701f4f17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Region Disaster Type Severity Parameter  Severity Value  \\\n",
            "0  Region_1    Earthquake          magnitude            7.98   \n",
            "1  Region_2       Drought   rainfall_deficit           33.36   \n",
            "2  Region_3       Drought   rainfall_deficit           75.70   \n",
            "3  Region_4         Storm         wind_speed           61.34   \n",
            "4  Region_5       Drought   rainfall_deficit           78.16   \n",
            "\n",
            "   Total Population  Age 0-12  Age 12-60  Age 60+  Female Population  \\\n",
            "0             77820     10210      41337    26273              35471   \n",
            "1             61263     14802      30883    15578              33510   \n",
            "2             68969      9404      37014    22551              33134   \n",
            "3             94016     14877      58512    20627              43618   \n",
            "4             60150     11501      39520     9129              28268   \n",
            "\n",
            "   Food Supply (kg)  Water Supply (liters)  Shelter Supply (tents)  \\\n",
            "0            389100                 233460                 15564.0   \n",
            "1            306315                 183789                 12252.6   \n",
            "2            344845                 206907                 13793.8   \n",
            "3            470080                 282048                 18803.2   \n",
            "4            300750                 180450                 12030.0   \n",
            "\n",
            "   Baby Food Supply (kg)  Medicine Supply (kits)  Sanitary Supply (items)  \n",
            "0                15315.0                   52546                    35471  \n",
            "1                22203.0                   31156                    33510  \n",
            "2                14106.0                   45102                    33134  \n",
            "3                22315.5                   41254                    43618  \n",
            "4                17251.5                   18258                    28268  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Define parameters for synthetic data generation\n",
        "num_regions = 1000  # Number of regions to simulate\n",
        "\n",
        "# Disaster types and their severity determining factors\n",
        "disaster_types = {\n",
        "    \"Flood\": {\"precipitation\": (50, 300)},  # in mm\n",
        "    \"Storm\": {\"wind_speed\": (60, 250)},  # in km/h\n",
        "    \"Earthquake\": {\"magnitude\": (4.0, 9.0)},  # Richter scale\n",
        "    \"Drought\": {\"rainfall_deficit\": (10, 80)},  # % decrease\n",
        "}\n",
        "\n",
        "# Supply factors per person\n",
        "food_per_person = 5  # kg\n",
        "water_per_person = 3  # liters\n",
        "shelter_per_person = 0.2  # tents per person\n",
        "medicine_per_elderly = 2  # medicine kits per 60+\n",
        "sanitary_items_per_female = 1  # per female\n",
        "baby_food_per_child = 1.5  # kg per 0-12 age child\n",
        "\n",
        "# Generate synthetic dataset\n",
        "np.random.seed(42)\n",
        "data = []\n",
        "\n",
        "for i in range(num_regions):\n",
        "    region_id = f\"Region_{i+1}\"\n",
        "    disaster = np.random.choice(list(disaster_types.keys()))\n",
        "    severity_param, (min_val, max_val) = list(disaster_types[disaster].items())[0]\n",
        "    severity_value = round(np.random.uniform(min_val, max_val), 2)\n",
        "\n",
        "    total_population = np.random.randint(1000, 100000)\n",
        "    age_0_12 = int(total_population * np.random.uniform(0.1, 0.3))\n",
        "    age_12_60 = int(total_population * np.random.uniform(0.5, 0.7))\n",
        "    age_60_plus = total_population - (age_0_12 + age_12_60)\n",
        "\n",
        "    female_ratio = np.random.uniform(0.45, 0.55)\n",
        "    female_population = int(total_population * female_ratio)\n",
        "\n",
        "    # Compute aid requirements\n",
        "    food_supply = total_population * food_per_person\n",
        "    water_supply = total_population * water_per_person\n",
        "    shelter_supply = total_population * shelter_per_person\n",
        "\n",
        "    baby_food_supply = age_0_12 * baby_food_per_child\n",
        "    medicine_supply = age_60_plus * medicine_per_elderly\n",
        "    sanitary_supply = female_population * sanitary_items_per_female\n",
        "\n",
        "    # Store data\n",
        "    data.append([\n",
        "        region_id, disaster, severity_param, severity_value, total_population,\n",
        "        age_0_12, age_12_60, age_60_plus, female_population,\n",
        "        food_supply, water_supply, shelter_supply,\n",
        "        baby_food_supply, medicine_supply, sanitary_supply\n",
        "    ])\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame(data, columns=[\n",
        "    \"Region\", \"Disaster Type\", \"Severity Parameter\", \"Severity Value\", \"Total Population\",\n",
        "    \"Age 0-12\", \"Age 12-60\", \"Age 60+\", \"Female Population\",\n",
        "    \"Food Supply (kg)\", \"Water Supply (liters)\", \"Shelter Supply (tents)\",\n",
        "    \"Baby Food Supply (kg)\", \"Medicine Supply (kits)\", \"Sanitary Supply (items)\"\n",
        "])\n",
        "\n",
        "# Save to CSV\n",
        "df.to_csv(\"disaster_relief_data.csv\", index=False)\n",
        "\n",
        "# Display sample data\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"disaster_relief_data.csv\")\n",
        "\n",
        "# Define features and target variables\n",
        "features = [\n",
        "    \"Disaster Type\", \"Severity Value\", \"Total Population\", \"Age 0-12\", \"Age 12-60\", \"Age 60+\", \"Female Population\"\n",
        "]\n",
        "targets = [\n",
        "    \"Food Supply (kg)\", \"Water Supply (liters)\", \"Shelter Supply (tents)\",\n",
        "    \"Baby Food Supply (kg)\", \"Medicine Supply (kits)\", \"Sanitary Supply (items)\"\n",
        "]\n",
        "\n",
        "X = df[features]\n",
        "y = df[targets]\n",
        "\n",
        "# Preprocessing: Encode categorical variables and scale numerical values\n",
        "categorical_features = [\"Disaster Type\"]\n",
        "numerical_features = [\"Severity Value\", \"Total Population\", \"Age 0-12\", \"Age 12-60\", \"Age 60+\", \"Female Population\"]\n",
        "\n",
        "preprocessor = ColumnTransformer([\n",
        "    (\"cat\", OneHotEncoder(handle_unknown='ignore'), categorical_features),\n",
        "    (\"num\", StandardScaler(), numerical_features)\n",
        "])\n",
        "\n",
        "# Define the model pipeline\n",
        "model = Pipeline([\n",
        "    (\"preprocessor\", preprocessor),\n",
        "    (\"regressor\", RandomForestRegressor(n_estimators=100, random_state=42))\n",
        "])\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = model.predict(X_test)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(f\"Mean Absolute Error: {mae:.2f}\")\n",
        "print(f\"R² Score: {r2:.2f}\")\n",
        "\n",
        "# Function to predict aid requirements for a new scenario\n",
        "def predict_aid(disaster, severity, population, age_0_12, age_12_60, age_60_plus, female_pop):\n",
        "    input_data = pd.DataFrame([[disaster, severity, population, age_0_12, age_12_60, age_60_plus, female_pop]], columns=features)\n",
        "    prediction = model.predict(input_data)\n",
        "    return dict(zip(targets, prediction[0]))\n",
        "\n",
        "# Example prediction\n",
        "example = predict_aid(\"Flood\", 180, 50000, 10000, 30000, 10000, 25000)\n",
        "print(\"Predicted Aid Requirements:\", example)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EzDiRokQ3LRQ",
        "outputId": "47dc5f99-b911-47d1-bc3e-4d25c6151321"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Error: 1048.74\n",
            "R² Score: 0.98\n",
            "Predicted Aid Requirements: {'Food Supply (kg)': np.float64(247680.75), 'Water Supply (liters)': np.float64(148608.45), 'Shelter Supply (tents)': np.float64(9907.23), 'Baby Food Supply (kg)': np.float64(14708.91), 'Medicine Supply (kits)': np.float64(20280.5), 'Sanitary Supply (items)': np.float64(24911.04)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"disaster_relief_data.csv\")\n",
        "\n",
        "# Define features and target variables\n",
        "features = [\n",
        "    \"Disaster Type\", \"Severity Value\", \"Total Population\", \"Age 0-12\", \"Age 12-60\", \"Age 60+\", \"Female Population\"\n",
        "]\n",
        "targets = [\n",
        "    \"Food Supply (kg)\", \"Water Supply (liters)\", \"Shelter Supply (tents)\",\n",
        "    \"Baby Food Supply (kg)\", \"Medicine Supply (kits)\", \"Sanitary Supply (items)\"\n",
        "]\n",
        "\n",
        "X = df[features]\n",
        "y = df[targets]\n",
        "\n",
        "# Preprocessing: Encode categorical variables and scale numerical values\n",
        "categorical_features = [\"Disaster Type\"]\n",
        "numerical_features = [\"Severity Value\", \"Total Population\", \"Age 0-12\", \"Age 12-60\", \"Age 60+\", \"Female Population\"]\n",
        "\n",
        "preprocessor = ColumnTransformer([\n",
        "    (\"cat\", OneHotEncoder(handle_unknown='ignore'), categorical_features),\n",
        "    (\"num\", StandardScaler(), numerical_features)\n",
        "])\n",
        "\n",
        "# Define the model pipeline\n",
        "pipeline = Pipeline([\n",
        "    (\"preprocessor\", preprocessor),\n",
        "    (\"regressor\", RandomForestRegressor(random_state=42))\n",
        "])\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Hyperparameter tuning with GridSearchCV\n",
        "param_grid = {\n",
        "    \"regressor__n_estimators\": [100, 200, 300],\n",
        "    \"regressor__max_depth\": [10, 20, None],\n",
        "    \"regressor__min_samples_split\": [2, 5, 10],\n",
        "    \"regressor__min_samples_leaf\": [1, 2, 4]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(pipeline, param_grid, cv=3, scoring=\"neg_mean_absolute_error\", n_jobs=-1, verbose=1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Best model\n",
        "tuned_model = grid_search.best_estimator_\n",
        "\n",
        "# Evaluate the tuned model\n",
        "y_pred = tuned_model.predict(X_test)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Optimized Mean Absolute Error: {mae:.2f}\")\n",
        "print(f\"Optimized R² Score: {r2:.2f}\")\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "\n",
        "# Function to predict aid requirements for a new scenario\n",
        "def predict_aid(disaster, severity, population, age_0_12, age_12_60, age_60_plus, female_pop):\n",
        "    input_data = pd.DataFrame([[disaster, severity, population, age_0_12, age_12_60, age_60_plus, female_pop]], columns=features)\n",
        "    prediction = tuned_model.predict(input_data)\n",
        "    return dict(zip(targets, prediction[0]))\n",
        "\n",
        "# Example prediction\n",
        "example = predict_aid(\"Flood\", 180, 50000, 10000, 30000, 10000, 25000)\n",
        "print(\"Predicted Aid Requirements:\", example)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIwbXWVZ3rcO",
        "outputId": "d38bf2e4-e885-444d-c385-e817bda01a7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 81 candidates, totalling 243 fits\n",
            "Optimized Mean Absolute Error: 1023.79\n",
            "Optimized R² Score: 0.98\n",
            "Best Parameters: {'regressor__max_depth': 10, 'regressor__min_samples_leaf': 1, 'regressor__min_samples_split': 2, 'regressor__n_estimators': 300}\n",
            "Predicted Aid Requirements: {'Food Supply (kg)': np.float64(246902.35), 'Water Supply (liters)': np.float64(148141.41), 'Shelter Supply (tents)': np.float64(9876.093999999997), 'Baby Food Supply (kg)': np.float64(14987.4775), 'Medicine Supply (kits)': np.float64(20087.076666666668), 'Sanitary Supply (items)': np.float64(24736.806666666667)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"disaster_relief_data.csv\")\n",
        "\n",
        "# Define features and target variables\n",
        "features = [\n",
        "    \"Disaster Type\", \"Severity Value\", \"Total Population\", \"Age 0-12\", \"Age 12-60\", \"Age 60+\", \"Female Population\"\n",
        "]\n",
        "targets = [\n",
        "    \"Food Supply (kg)\", \"Water Supply (liters)\", \"Shelter Supply (tents)\",\n",
        "    \"Baby Food Supply (kg)\", \"Medicine Supply (kits)\", \"Sanitary Supply (items)\"\n",
        "]\n",
        "\n",
        "X = df[features]\n",
        "y = df[targets]\n",
        "\n",
        "# Preprocessing: Encode categorical variables and scale numerical values\n",
        "categorical_features = [\"Disaster Type\"]\n",
        "numerical_features = [\"Severity Value\", \"Total Population\", \"Age 0-12\", \"Age 12-60\", \"Age 60+\", \"Female Population\"]\n",
        "\n",
        "preprocessor = ColumnTransformer([\n",
        "    (\"cat\", OneHotEncoder(handle_unknown='ignore'), categorical_features),\n",
        "    (\"num\", StandardScaler(), numerical_features)\n",
        "])\n",
        "\n",
        "# Define the model pipeline\n",
        "pipeline = Pipeline([\n",
        "    (\"preprocessor\", preprocessor),\n",
        "    (\"regressor\", RandomForestRegressor(random_state=42))\n",
        "])\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Hyperparameter tuning with GridSearchCV\n",
        "param_grid = {\n",
        "    \"regressor__n_estimators\": [100, 200, 300],\n",
        "    \"regressor__max_depth\": [10, 20, None],\n",
        "    \"regressor__min_samples_split\": [2, 5, 10],\n",
        "    \"regressor__min_samples_leaf\": [1, 2, 4]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(pipeline, param_grid, cv=3, scoring=\"neg_mean_absolute_error\", n_jobs=-1, verbose=1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Best model\n",
        "tuned_model = grid_search.best_estimator_\n",
        "\n",
        "# Evaluate the tuned model\n",
        "y_train_pred = tuned_model.predict(X_train)\n",
        "y_test_pred = tuned_model.predict(X_test)\n",
        "\n",
        "mae = mean_absolute_error(y_test, y_test_pred)\n",
        "r2_train = r2_score(y_train, y_train_pred)\n",
        "r2_test = r2_score(y_test, y_test_pred)\n",
        "\n",
        "print(f\"Optimized Mean Absolute Error: {mae:.2f}\")\n",
        "print(f\"Train R² Score: {r2_train:.2f}\")\n",
        "print(f\"Test R² Score: {r2_test:.2f}\")\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "\n",
        "# Function to predict aid requirements for a new scenario\n",
        "def predict_aid(disaster, severity, population, age_0_12, age_12_60, age_60_plus, female_pop):\n",
        "    input_data = pd.DataFrame([[disaster, severity, population, age_0_12, age_12_60, age_60_plus, female_pop]], columns=features)\n",
        "    prediction = tuned_model.predict(input_data)\n",
        "    return dict(zip(targets, prediction[0]))\n",
        "\n",
        "# Example prediction\n",
        "example = predict_aid(\"Flood\", 180, 50000, 10000, 30000, 10000, 25000)\n",
        "print(\"Predicted Aid Requirements:\", example)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60F30YPg4sex",
        "outputId": "db4a7e00-97c7-4dac-b4e2-400f674a06da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 81 candidates, totalling 243 fits\n",
            "Optimized Mean Absolute Error: 1023.79\n",
            "Train R² Score: 1.00\n",
            "Test R² Score: 0.98\n",
            "Best Parameters: {'regressor__max_depth': 10, 'regressor__min_samples_leaf': 1, 'regressor__min_samples_split': 2, 'regressor__n_estimators': 300}\n",
            "Predicted Aid Requirements: {'Food Supply (kg)': np.float64(246902.35), 'Water Supply (liters)': np.float64(148141.41), 'Shelter Supply (tents)': np.float64(9876.093999999997), 'Baby Food Supply (kg)': np.float64(14987.4775), 'Medicine Supply (kits)': np.float64(20087.076666666668), 'Sanitary Supply (items)': np.float64(24736.806666666667)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score, mean_absolute_error\n",
        "\n",
        "# Predict on training and testing data\n",
        "y_train_pred = tuned_model.predict(X_train)\n",
        "y_test_pred = tuned_model.predict(X_test)\n",
        "\n",
        "# Calculate R² scores\n",
        "r2_train = r2_score(y_train, y_train_pred)\n",
        "r2_test = r2_score(y_test, y_test_pred)\n",
        "\n",
        "# Calculate Mean Absolute Error (MAE)\n",
        "mae_train = mean_absolute_error(y_train, y_train_pred)\n",
        "mae_test = mean_absolute_error(y_test, y_test_pred)\n",
        "\n",
        "# Print results\n",
        "print(f\"Train R² Score: {r2_train:.2f}\")\n",
        "print(f\"Test R² Score: {r2_test:.2f}\")\n",
        "print(f\"Train MAE: {mae_train:.2f}\")\n",
        "print(f\"Test MAE: {mae_test:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-2dx1RbZMzn",
        "outputId": "0f5cc226-0ba0-4120-c4b9-35ba704b0c94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train R² Score: 1.00\n",
            "Test R² Score: 0.98\n",
            "Train MAE: 438.29\n",
            "Test MAE: 1023.79\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define parameter grid for tuning\n",
        "param_grid = {\n",
        "    \"regressor__n_estimators\": [50, 100, 200],  # Reduce the number of trees\n",
        "    \"regressor__max_depth\": [5, 10, 15],  # Limit tree depth to prevent overfitting\n",
        "    \"regressor__min_samples_split\": [5, 10, 15],  # Require more samples to split\n",
        "    \"regressor__min_samples_leaf\": [2, 4, 6]  # Require more samples in leaf nodes\n",
        "}\n",
        "\n",
        "# Grid search with cross-validation\n",
        "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring=\"neg_mean_absolute_error\", n_jobs=-1, verbose=1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Best model after tuning\n",
        "tuned_model = grid_search.best_estimator_\n",
        "\n",
        "# Evaluate the tuned model\n",
        "y_train_pred = tuned_model.predict(X_train)\n",
        "y_test_pred = tuned_model.predict(X_test)\n",
        "\n",
        "r2_train = r2_score(y_train, y_train_pred)\n",
        "r2_test = r2_score(y_test, y_test_pred)\n",
        "\n",
        "print(f\"Optimized Train R² Score: {r2_train:.2f}\")\n",
        "print(f\"Optimized Test R² Score: {r2_test:.2f}\")\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDSbZj4aZ8E2",
        "outputId": "e6eb11d3-11a1-4712-eac0-ced1d4a4a556"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
            "Optimized Train R² Score: 0.99\n",
            "Optimized Test R² Score: 0.98\n",
            "Best Parameters: {'regressor__max_depth': 15, 'regressor__min_samples_leaf': 2, 'regressor__min_samples_split': 5, 'regressor__n_estimators': 200}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define parameter grid for tuning (more restrictions)\n",
        "param_grid = {\n",
        "    \"regressor__n_estimators\": [50, 100],  # Reduce tree count\n",
        "    \"regressor__max_depth\": [5, 10],  # Reduce depth to prevent memorization\n",
        "    \"regressor__min_samples_split\": [10, 20],  # Require more samples to split\n",
        "    \"regressor__min_samples_leaf\": [5, 10]  # Require larger leaf nodes\n",
        "}\n",
        "\n",
        "# Grid search with cross-validation\n",
        "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring=\"neg_mean_absolute_error\", n_jobs=-1, verbose=1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Best model after tuning\n",
        "tuned_model = grid_search.best_estimator_\n",
        "\n",
        "# Evaluate the tuned model\n",
        "y_train_pred = tuned_model.predict(X_train)\n",
        "y_test_pred = tuned_model.predict(X_test)\n",
        "\n",
        "r2_train = r2_score(y_train, y_train_pred)\n",
        "r2_test = r2_score(y_test, y_test_pred)\n",
        "\n",
        "print(f\"Optimized Train R² Score: {r2_train:.2f}\")\n",
        "print(f\"Optimized Test R² Score: {r2_test:.2f}\")\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2s__yYIaa-PJ",
        "outputId": "01b62064-42ce-426f-977b-71e29b708a59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
            "Optimized Train R² Score: 0.97\n",
            "Optimized Test R² Score: 0.96\n",
            "Best Parameters: {'regressor__max_depth': 10, 'regressor__min_samples_leaf': 5, 'regressor__min_samples_split': 10, 'regressor__n_estimators': 100}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score, mean_absolute_error\n",
        "\n",
        "# Predict on training and testing data\n",
        "y_train_pred = tuned_model.predict(X_train)\n",
        "y_test_pred = tuned_model.predict(X_test)\n",
        "\n",
        "# Calculate R² scores\n",
        "r2_train = r2_score(y_train, y_train_pred)\n",
        "r2_test = r2_score(y_test, y_test_pred)\n",
        "\n",
        "# Calculate Mean Absolute Error (MAE)\n",
        "mae_train = mean_absolute_error(y_train, y_train_pred)\n",
        "mae_test = mean_absolute_error(y_test, y_test_pred)\n",
        "\n",
        "# Print results\n",
        "print(f\"Train R² Score: {r2_train:.2f}\")\n",
        "print(f\"Test R² Score: {r2_test:.2f}\")\n",
        "print(f\"Train MAE: {mae_train:.2f}\")\n",
        "print(f\"Test MAE: {mae_test:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Le6GM_8-B50y",
        "outputId": "4a51e2c5-11ff-48e2-c591-806366145d90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train R² Score: 0.97\n",
            "Test R² Score: 0.96\n",
            "Train MAE: 1246.25\n",
            "Test MAE: 1432.97\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example test case: Predict aid requirements for a new disaster scenario\n",
        "example_scenario = {\n",
        "    \"Disaster Type\": \"Flood\",  # Disaster type (categorical)\n",
        "    \"Severity Value\": 150,  # Severity of disaster\n",
        "    \"Total Population\": 60000,  # Total people affected\n",
        "    \"Age 0-12\": 12000,  # Children\n",
        "    \"Age 12-60\": 40000,  # Adults\n",
        "    \"Age 60+\": 8000,  # Elderly\n",
        "    \"Female Population\": 30000  # Number of females in affected area\n",
        "}\n",
        "\n",
        "# Convert example input to DataFrame\n",
        "example_df = pd.DataFrame([example_scenario])\n",
        "\n",
        "# Predict using the tuned model\n",
        "predicted_aid = tuned_model.predict(example_df)\n",
        "\n",
        "# Display predictions\n",
        "predicted_result = dict(zip(targets, predicted_aid[0]))\n",
        "# print(\"Predicted Aid Requirements:\", predicted_result)\n",
        "# Convert predicted results to a readable format\n",
        "predicted_result_clean = {key: round(float(value)) for key, value in predicted_result.items()}\n",
        "\n",
        "# Print clean output\n",
        "print(\"Predicted Aid Requirements:\", predicted_result_clean)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "baheLQuKcJSE",
        "outputId": "87789869-33a2-4924-ee37-82746bbdebfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Aid Requirements: {'Food Supply (kg)': 299961, 'Water Supply (liters)': 179976, 'Shelter Supply (tents)': 11998, 'Baby Food Supply (kg)': 21270, 'Medicine Supply (kits)': 14782, 'Sanitary Supply (items)': 29628}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "# Expanded parameter grid for better fine-tuning\n",
        "param_grid = {\n",
        "    \"regressor__n_estimators\": [50, 100, 150, 200],  # More trees to balance bias-variance\n",
        "    \"regressor__max_depth\": [5, 10, 15, 20],  # More depth options to optimize model complexity\n",
        "    \"regressor__min_samples_split\": [5, 10, 15, 20],  # Ensure enough data per split\n",
        "    \"regressor__min_samples_leaf\": [2, 5, 10, 15]  # Larger leaves to reduce overfitting\n",
        "}\n",
        "\n",
        "# Randomized Search for faster tuning\n",
        "random_search = RandomizedSearchCV(\n",
        "    pipeline, param_grid, cv=5, scoring=\"neg_mean_absolute_error\",\n",
        "    n_jobs=-1, verbose=1, n_iter=20, random_state=42\n",
        ")\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Best model after tuning\n",
        "tuned_model = random_search.best_estimator_\n",
        "\n",
        "# Evaluate the tuned model\n",
        "y_train_pred = tuned_model.predict(X_train)\n",
        "y_test_pred = tuned_model.predict(X_test)\n",
        "\n",
        "# Calculate R² scores and MAE\n",
        "r2_train = r2_score(y_train, y_train_pred)\n",
        "r2_test = r2_score(y_test, y_test_pred)\n",
        "mae_train = mean_absolute_error(y_train, y_train_pred)\n",
        "mae_test = mean_absolute_error(y_test, y_test_pred)\n",
        "\n",
        "# Print results\n",
        "print(f\"Optimized Train R² Score: {r2_train:.2f}\")\n",
        "print(f\"Optimized Test R² Score: {r2_test:.2f}\")\n",
        "print(f\"Optimized Train MAE: {mae_train:.2f}\")\n",
        "print(f\"Optimized Test MAE: {mae_test:.2f}\")\n",
        "print(\"Best Parameters:\", random_search.best_params_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJoP7tMwB9Jq",
        "outputId": "57a470c4-572a-4f31-97e2-7e9183adf29c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
            "Optimized Train R² Score: 0.98\n",
            "Optimized Test R² Score: 0.97\n",
            "Optimized Train MAE: 1225.34\n",
            "Optimized Test MAE: 1416.69\n",
            "Best Parameters: {'regressor__n_estimators': 200, 'regressor__min_samples_split': 10, 'regressor__min_samples_leaf': 2, 'regressor__max_depth': 20}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from prettytable import PrettyTable\n",
        "\n",
        "# Example test case: Predict aid requirements for a new disaster scenario\n",
        "example_scenario = {\n",
        "    \"Disaster Type\": \"Flood\",  # Disaster type (categorical)\n",
        "    \"Severity Value\": 150,  # Severity of disaster\n",
        "    \"Total Population\": 60000,  # Total people affected\n",
        "    \"Age 0-12\": 12000,  # Children\n",
        "    \"Age 12-60\": 40000,  # Adults\n",
        "    \"Age 60+\": 8000,  # Elderly\n",
        "    \"Female Population\": 30000  # Number of females in affected area\n",
        "}\n",
        "\n",
        "# Convert example input to DataFrame\n",
        "example_df = pd.DataFrame([example_scenario])\n",
        "\n",
        "# Predict using the tuned model\n",
        "predicted_aid = tuned_model.predict(example_df)\n",
        "\n",
        "# Convert predictions to a readable format\n",
        "predicted_result = dict(zip(targets, predicted_aid[0]))\n",
        "predicted_result_clean = {key: round(float(value)) for key, value in predicted_result.items()}\n",
        "\n",
        "# Create a table for better visualization\n",
        "table = PrettyTable()\n",
        "table.field_names = [\"Aid Type\", \"Predicted Quantity\"]\n",
        "\n",
        "for key, value in predicted_result_clean.items():\n",
        "    table.add_row([key, value])\n",
        "\n",
        "# Print the organized table\n",
        "print(\"\\n📌 Predicted Aid Requirements for Disaster Scenario\\n\")\n",
        "print(table)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2X5X2wWkB_kJ",
        "outputId": "e86c7e24-aeab-4371-c8ef-20168b8afe4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📌 Predicted Aid Requirements for Disaster Scenario\n",
            "\n",
            "+-------------------------+--------------------+\n",
            "|         Aid Type        | Predicted Quantity |\n",
            "+-------------------------+--------------------+\n",
            "|     Food Supply (kg)    |       299804       |\n",
            "|  Water Supply (liters)  |       179882       |\n",
            "|  Shelter Supply (tents) |       11992        |\n",
            "|  Baby Food Supply (kg)  |       20772        |\n",
            "|  Medicine Supply (kits) |       16808        |\n",
            "| Sanitary Supply (items) |       29602        |\n",
            "+-------------------------+--------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Save the trained model\n",
        "filename = \"disaster_relief_model.pkl\"\n",
        "with open(filename, \"wb\") as file:\n",
        "    pickle.dump(tuned_model, file)\n",
        "\n",
        "print(\"Model saved as:\", filename)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tq54bNaCCHWQ",
        "outputId": "d20569e9-99b6-492c-a4a3-7cd987650212"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved as: disaster_relief_model.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hzH-sGQdDO5P"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}